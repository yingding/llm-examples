{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dce6ec1-4e23-4d4c-b2b7-6c2de9b465c5",
   "metadata": {},
   "source": [
    "# Language Translation German to English\n",
    "\n",
    "## English to German with T5\n",
    "* T5 https://huggingface.co/docs/transformers/model_doc/t5\n",
    "* Translation intro course https://huggingface.co/learn/nlp-course/chapter7/4?fw=tf\n",
    "* Two way translation with T5 discussion: https://stackoverflow.com/questions/66797042/using-googles-t5-for-translation-from-german-to-english\n",
    "* Model capability output example: https://github.com/PacktPublishing/Transformers-for-Natural-Language-Processing/blob/main/Chapter07/Summarizing_Text_with_T5.ipynb\n",
    "\n",
    "\n",
    "## German to English with mT5\n",
    "* https://huggingface.co/docs/transformers/model_doc/mt5\n",
    "* https://huggingface.co/docs/transformers/model_doc/mt5#transformers.MT5ForConditionalGeneration\n",
    "* https://huggingface.co/transformers/v4.9.2/model_doc/mt5.html\n",
    "\n",
    "## German to English custom model\n",
    "* https://stackoverflow.com/questions/66797042/using-googles-t5-for-translation-from-german-to-english\n",
    "\n",
    "## MarianMT \n",
    "* BART Translate: https://huggingface.co/docs/transformers/model_doc/marian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85ef3af-bda8-435c-96cd-55ff0ae716dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA A100 80GB PCIe (UUID: GPU-51f84540-9ebb-1d44-7bb7-3c62ae55c20e)\n",
      "  MIG 2g.20gb     Device  0: (UUID: MIG-f1e32298-70d4-52fc-9b1d-21a178d44529)\n"
     ]
    }
   ],
   "source": [
    "list=!nvidia-smi -L\n",
    "for i in range(len(list)):\n",
    "    print(list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e9f28f-d517-44fc-a91e-832ee2516760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIG-f1e32298-70d4-52fc-9b1d-21a178d44529\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def get_device_uuid(input: str) -> str:\n",
    "    try:\n",
    "        # r'' before the search pattern indicates it is a raw string, \n",
    "        # otherwise \"\" instead of single quote\n",
    "        uuid = re.search(r'UUID\\:\\s(.+?)\\)', input).group(1)\n",
    "    except AttributeError:\n",
    "        # \"UUID\\:\\s\" and \"\\)\" not found\n",
    "        uuid = \"\"\n",
    "    return uuid    \n",
    "\n",
    "# skip the first GPU ID, only get the MIG IDs, using python list slice over index access\n",
    "uuid_list = [get_device_uuid(e) for e in list[1:]]\n",
    "# print(uuid_list)\n",
    "UUIDs = \",\".join(uuid_list)\n",
    "print(UUIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c714714-0c21-499d-af92-be62f99e83a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIG-f1e32298-70d4-52fc-9b1d-21a178d44529\n",
      "3.8.10\n"
     ]
    }
   ],
   "source": [
    "import os, time, sys\n",
    "from platform import python_version\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = UUIDs # \"0,1,2\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\" #512\n",
    "display_architecture=True\n",
    "\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc8923a3-d0e5-494e-86de-a0eeb0de80e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the model download cache directory\n",
    "# DATA_ROOT=\"/data\"\n",
    "DATA_ROOT=\"/home/jovyan/llm-models\"\n",
    "os.environ['XDG_CACHE_HOME']=f\"{DATA_ROOT}/core-kind/yinwang/models\"\n",
    "\n",
    "model_map = {\n",
    "   \"small\": \"google/mt5-small\", # 1.2 GB\n",
    "   \"base\" : \"google/mt5-base\", # 2.33 GB\n",
    "   \"large\" : \"google/mt5-large\", # 4.9 GB,\n",
    "   \"xl\" : \"google/mt5-xl\", # 15 GB\n",
    "   \"xxl\" : \"google/mt5-xxl\", # 51.7 GB,\n",
    "   \"custom\": \"Helsinki-NLP/opus-mt-de-en\", \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80fe33ad-666c-4794-9afa-c5b515458cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helsinki-NLP/opus-mt-de-en\n"
     ]
    }
   ],
   "source": [
    "model_type = \"custom\"\n",
    "model_name = model_map.get(model_type, \"small\")\n",
    "\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb65c33-4b8c-466f-985a-3f8d7789d079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "068283d6-c0a3-414a-a5ab-71a39978fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "device_map=\"auto\" doesn't work with \"Helsinki-NLP/opus-mt-de-en\" translator model\n",
    "use explicit gpu device id 0 with device=0\n",
    "'''\n",
    "generator = pipeline(\n",
    "    \"translation\", \n",
    "    model=model_name,\n",
    "    # device_map=\"auto\",\n",
    "    device=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35516616-a921-419e-80df-276ed6685e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.pipelines.text2text_generation.TranslationPipeline"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea74988-7764-41a6-ae20-a685d708bed9",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24cc4e14-da3c-4b3a-a9e0-a1abb4e7f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.gpu_utils import GPUInfoHelper\n",
    "\n",
    "gpu_info_helper = GPUInfoHelper()\n",
    "# task_prefix = \"translate English to German: \"\n",
    "# task_prefix = \"translate German to English: \"\n",
    "# task_prefix = \"Ã¼bersetze Deutsch zum Englisch: \"\n",
    "# Reference: https://huggingface.co/docs/transformers/model_doc/marian\n",
    "def translate_gen(\n",
    "    generator: transformers.pipelines.text2text_generation.TranslationPipeline, \n",
    "    info: GPUInfoHelper,\n",
    "):  \n",
    "    \"\"\"\n",
    "    Args:\n",
    "      max_new_tokens: control the maximum length of the generation\n",
    "    \"\"\"\n",
    "    \n",
    "    def local(sentences: list, max_length=400) -> list:\n",
    "        \"\"\"single input, no batch input\n",
    "        Args:\n",
    "          sentences:\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        \n",
    "        result = generator(\n",
    "            sentences, \n",
    "            max_length=max_length,\n",
    "            # return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        end = time.time()\n",
    "        duration = end - start\n",
    "        print(\"-\"*20)\n",
    "        print(f\"walltime: {duration} in secs.\")\n",
    "        info.gpu_usage()\n",
    "        \n",
    "        return result\n",
    "    return local    \n",
    "\n",
    "translate = translate_gen(generator, gpu_info_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "488da92f-4200-4f40-ac47-fe0db1da39a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input=\"Das Haus ist wunderbar.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "887eded6-4d0a-4bba-822e-c66d2a690bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "walltime: 0.6826529502868652 in secs.\n",
      "num_of_gpus: 1\n",
      "--------------------\n",
      "Device_name      : NVIDIA A100 80GB PCIe MIG 2g.20gb \n",
      "Multi_processor  : 28\n",
      "Physical  memory : 19.500000 GB\n",
      "Reserved  memory : 0.310547 GB\n",
      "Allocated memory : 0.285861 GB\n",
      "Free      memory : 0.024686 GB\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'The house is wonderful.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit\n",
    "translate(input, max_length=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab2d3a3f-1697-4f9d-8d01-cd163bfe16f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/llm-models/core-kind/yinwang/data/medreports\n"
     ]
    }
   ],
   "source": [
    "from pdf_text_loader import PDFHelper\n",
    "# DATA_ROOT=\"/home/jovyan/llm-models\"\n",
    "DATA_SUBDIR=\"core-kind/yinwang/data/medreports\"\n",
    "print(f\"{DATA_ROOT}/{DATA_SUBDIR}\")\n",
    "loader = PDFHelper(data_folder = f\"{DATA_ROOT}/{DATA_SUBDIR}\", file_pattern=\"KK-SCIVIAS-*.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "625e18a2-f66f-42aa-8a44-6096ec650859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/jovyan/llm-models/core-kind/yinwang/data/medreports/KK-SCIVIAS-00004-0054584394-2021-01-17.pdf',\n",
       " '/home/jovyan/llm-models/core-kind/yinwang/data/medreports/KK-SCIVIAS-00004-0051726752-2015-12-17.pdf']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.file_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d030e7c2-39c3-4ddb-b635-ecc013eb3191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# has two testing file, choose the pdf file to be tranlated with list index\n",
    "# file_idx = 0\n",
    "file_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d66f77e1-54ce-4b0e-96a3-f5640e7e0906",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = loader.read_pdf(file_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08bd05d2-dd9f-43e3-8286-a778d0e67183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file: /home/jovyan/llm-models/core-kind/yinwang/data/medreports/KK-SCIVIAS-00004-0051726752-2015-12-17.pdf\n",
      "total token: 17545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17545"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader.count_token(file_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74b62873-f582-4496-9a2e-b60b096f7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/13673060/split-string-into-strings-by-length\n",
    "def wrap(s, w):\n",
    "    \"\"\"\n",
    "    split string with length w into a list of strings with length w\n",
    "    Arge:\n",
    "      s: orginial str\n",
    "      w: with of the each split for the string\n",
    "      \n",
    "    Return:\n",
    "      a list of string with each element as string of length w\n",
    "    \"\"\"\n",
    "    return [s[i:i + w] for i in range(0, len(s), w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b86dcae2-1dc5-4dd2-a442-a0193f84545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_content = wrap(context, 350)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db6025db-bfd6-4994-abe5-ebdaa8e3e355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splitted_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe9801-a177-423e-8622-70d8d9eda1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "walltime: 0.5943231582641602 in secs.\n",
      "num_of_gpus: 1\n",
      "--------------------\n",
      "Device_name      : NVIDIA A100 80GB PCIe MIG 2g.20gb \n",
      "Multi_processor  : 28\n",
      "Physical  memory : 19.500000 GB\n",
      "Reserved  memory : 0.357422 GB\n",
      "Allocated memory : 0.285861 GB\n",
      "Free      memory : 0.071561 GB\n",
      "--------------------\n",
      "--------------------\n",
      "walltime: 0.5205059051513672 in secs.\n",
      "num_of_gpus: 1\n",
      "--------------------\n",
      "Device_name      : NVIDIA A100 80GB PCIe MIG 2g.20gb \n",
      "Multi_processor  : 28\n",
      "Physical  memory : 19.500000 GB\n",
      "Reserved  memory : 0.357422 GB\n",
      "Allocated memory : 0.285861 GB\n",
      "Free      memory : 0.071561 GB\n",
      "--------------------\n",
      "--------------------\n",
      "walltime: 0.41490697860717773 in secs.\n",
      "num_of_gpus: 1\n",
      "--------------------\n",
      "Device_name      : NVIDIA A100 80GB PCIe MIG 2g.20gb \n",
      "Multi_processor  : 28\n",
      "Physical  memory : 19.500000 GB\n",
      "Reserved  memory : 0.357422 GB\n",
      "Allocated memory : 0.285861 GB\n",
      "Free      memory : 0.071561 GB\n",
      "--------------------\n",
      "--------------------\n",
      "walltime: 0.37788915634155273 in secs.\n",
      "num_of_gpus: 1\n",
      "--------------------\n",
      "Device_name      : NVIDIA A100 80GB PCIe MIG 2g.20gb \n",
      "Multi_processor  : 28\n",
      "Physical  memory : 19.500000 GB\n",
      "Reserved  memory : 0.357422 GB\n",
      "Allocated memory : 0.285861 GB\n",
      "Free      memory : 0.071561 GB\n",
      "--------------------\n",
      "--------------------\n",
      "walltime: 0.1917715072631836 in secs.\n",
      "num_of_gpus: 1\n",
      "--------------------\n",
      "Device_name      : NVIDIA A100 80GB PCIe MIG 2g.20gb \n",
      "Multi_processor  : 28\n",
      "Physical  memory : 19.500000 GB\n",
      "Reserved  memory : 0.357422 GB\n",
      "Allocated memory : 0.285861 GB\n",
      "Free      memory : 0.071561 GB\n",
      "--------------------\n",
      "--------------------\n",
      "walltime: 0.3509654998779297 in secs.\n",
      "num_of_gpus: 1\n",
      "--------------------\n",
      "Device_name      : NVIDIA A100 80GB PCIe MIG 2g.20gb \n",
      "Multi_processor  : 28\n",
      "Physical  memory : 19.500000 GB\n",
      "Reserved  memory : 0.357422 GB\n",
      "Allocated memory : 0.285861 GB\n",
      "Free      memory : 0.071561 GB\n",
      "--------------------\n",
      "--------------------\n",
      "walltime: 0.31847572326660156 in secs.\n",
      "num_of_gpus: 1\n",
      "--------------------\n",
      "Device_name      : NVIDIA A100 80GB PCIe MIG 2g.20gb \n",
      "Multi_processor  : 28\n",
      "Physical  memory : 19.500000 GB\n",
      "Reserved  memory : 0.357422 GB\n",
      "Allocated memory : 0.285861 GB\n",
      "Free      memory : 0.071561 GB\n",
      "--------------------\n",
      "--------------------\n",
      "walltime: 0.4935007095336914 in secs.\n",
      "num_of_gpus: 1\n",
      "--------------------\n",
      "Device_name      : NVIDIA A100 80GB PCIe MIG 2g.20gb \n",
      "Multi_processor  : 28\n",
      "Physical  memory : 19.500000 GB\n",
      "Reserved  memory : 0.357422 GB\n",
      "Allocated memory : 0.285861 GB\n",
      "Free      memory : 0.071561 GB\n",
      "--------------------\n",
      "--------------------\n",
      "walltime: 0.2913060188293457 in secs.\n",
      "num_of_gpus: 1\n",
      "--------------------\n",
      "Device_name      : NVIDIA A100 80GB PCIe MIG 2g.20gb \n",
      "Multi_processor  : 28\n",
      "Physical  memory : 19.500000 GB\n",
      "Reserved  memory : 0.357422 GB\n",
      "Allocated memory : 0.285861 GB\n",
      "Free      memory : 0.071561 GB\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1083: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for input in splitted_content:\n",
    "    output.append(translate(input)[0].get('translation_text', '').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf89997-8f01-4488-814d-be1484f1ac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_content = ''.join(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c54680c-40e1-4523-a662-abf8e1254a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(en_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a0655-4eb0-421e-be36-2a658f8a4fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the translated text has tokens: {len(en_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f3fd25-0f27-4aae-bf25-84daabeebd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_txt(content, path):\n",
    "    with open (path, \"w\") as text_file:\n",
    "        #write string to file\n",
    "        text_file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbb2618-e327-44ba-a92f-ca887b22f7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_txt_path = loader.file_path_list[file_idx].replace(\"pdf\", \"txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1eadac-b5c6-4a85-ab6c-beb9f1c8a11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_txt(en_content, en_txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dea4bd-4cab-4391-800a-d78885f21442",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
